{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/DragGAN-colab/blob/main/draggan_custom_author_colab.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "!pip install gradio==3.35.2 einops==0.4.1 fused==0.1.0 glfw==2.2.0 imgui==1.3.0 lmdb==1.3.0 mmcv==1.3.15 pypng==0.20220715.0 pyspng==0.1.1 ninja==1.11.1 wandb lpips\n",
    "\n",
    "!git clone https://github.com/camenduru/PTI\n",
    "!mkdir /content/PTI/pretrained_models\n",
    "!wget https://huggingface.co/camenduru/PTI/resolve/main/align.dat -O /content/PTI/pretrained_models/align.dat\n",
    "!wget https://huggingface.co/camenduru/PTI/resolve/main/ffhq.pkl -O /content/PTI/pretrained_models/ffhq.pkl\n",
    "!wget https://huggingface.co/camenduru/PTI/resolve/main/e4e_ffhq_encode.pt -O /content/PTI/pretrained_models/e4e_ffhq_encode.pt\n",
    "\n",
    "%cd /content/PTI\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from configs import paths_config, hyperparameters, global_config\n",
    "from utils.align_data import pre_process_images\n",
    "from scripts.run_pti import run_PTI\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.latent_editor_wrapper import LatentEditorWrapper\n",
    "\n",
    "paths_config.input_data_path\n",
    "image_dir_name = 'image'\n",
    "use_image_online = True\n",
    "image_name = 'image'\n",
    "use_multi_id_training = False\n",
    "global_config.device = 'cuda'\n",
    "paths_config.e4e = '/content/PTI/pretrained_models/e4e_ffhq_encode.pt'\n",
    "paths_config.input_data_id = image_dir_name\n",
    "paths_config.input_data_path = f'/content/PTI/{image_dir_name}_processed'\n",
    "paths_config.stylegan2_ada_ffhq = '/content/PTI/pretrained_models/ffhq.pkl'\n",
    "paths_config.checkpoints_dir = '/content/PTI/'\n",
    "paths_config.style_clip_pretrained_mappers = '/content/PTI/pretrained_models'\n",
    "hyperparameters.use_locality_regularization = False\n",
    "\n",
    "!mkdir /content/PTI/{image_dir_name}_original\n",
    "!mkdir /content/PTI/{image_dir_name}_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please add you image to /content/PTI/image_original/image.png\n",
    "\n",
    "original_image = Image.open(f'/content/PTI/image_original/{image_name}.jpg')\n",
    "# original_image\n",
    "pre_process_images(f'/content/PTI/{image_dir_name}_original')\n",
    "\n",
    "aligned_image = Image.open(f'/content/PTI/{image_dir_name}_processed/{image_name}.jpeg')\n",
    "# aligned_image.resize((512,512))\n",
    "\n",
    "model_id = run_PTI(use_wandb=False, use_multi_id_training=use_multi_id_training)\n",
    "\n",
    "def load_generators(model_id, image_name):\n",
    "  with open(paths_config.stylegan2_ada_ffhq, 'rb') as f:\n",
    "    old_G = pickle.load(f)['G_ema'].cuda()\n",
    "\n",
    "  with open(f'{paths_config.checkpoints_dir}/model_{model_id}_{image_name}.pt', 'rb') as f_new:\n",
    "    new_G = torch.load(f_new).cuda()\n",
    "\n",
    "  return old_G, new_G\n",
    "\n",
    "generator_type = paths_config.multi_id_model_type if use_multi_id_training else image_name\n",
    "old_G, new_G = load_generators(model_id, generator_type)\n",
    "\n",
    "def export_updated_pickle(new_G,model_id):\n",
    "  print(\"Exporting large updated pickle based off new generator and ffhq.pkl\")\n",
    "  with open(paths_config.stylegan2_ada_ffhq, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    old_G = d['G_ema'].cuda() ## tensor\n",
    "    old_D = d['D'].eval().requires_grad_(False).cpu()\n",
    "\n",
    "  tmp = {}\n",
    "  tmp['G'] = old_G.eval().requires_grad_(False).cpu() # copy.deepcopy(new_G).eval().requires_grad_(False).cpu()\n",
    "  tmp['G_ema'] = new_G.eval().requires_grad_(False).cpu() # copy.deepcopy(new_G).eval().requires_grad_(False).cpu()\n",
    "  tmp['D'] = old_D\n",
    "  tmp['training_set_kwargs'] = None\n",
    "  tmp['augment_pipe'] = None\n",
    "\n",
    "  with open(f'{paths_config.checkpoints_dir}/stylegan2_custom_512_pytorch.pkl', 'wb') as f:\n",
    "      pickle.dump(tmp, f)\n",
    "\n",
    "export_updated_pickle(new_G,model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone -b dev1 https://github.com/camenduru/DragGAN\n",
    "%cd /content/DragGAN\n",
    "!pip install -r requirements.txt\n",
    "# !pip install gradio==3.35.2 einops==0.4.1 fused==0.1.0 glfw==2.2.0 imgui==1.3.0 lmdb==1.3.0 mmcv==1.3.15 pypng==0.20220715.0 pyspng==0.1.1 ninja==1.11.1\n",
    "# !pip install -U scipy==1.11.0 Ninja==1.10.2 gradio>=3.35.2 imageio-ffmpeg>=0.4.3 huggingface_hub hf_transfer pyopengl imgui glfw==2.6.1 pillow>=9.4.0 imageio>=2.9.0 wandb lpips\n",
    "\n",
    "!apt -y install -qq aria2\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan2-afhqcat-512x512.pkl -d /content/DragGAN/checkpoints -o stylegan2-afhqcat-512x512.pkl\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan2-car-config-f.pkl -d /content/DragGAN/checkpoints -o stylegan2-car-config-f.pkl\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan2-cat-config-f.pkl -d /content/DragGAN/checkpoints -o stylegan2-cat-config-f.pkl\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan2-ffhq-512x512.pkl -d /content/DragGAN/checkpoints -o stylegan2-ffhq-512x512.pkl\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan2-lhq-256x256.pkl -d /content/DragGAN/checkpoints -o stylegan2-lhq-256x256.pkl\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan2_dogs_1024_pytorch.pkl -d /content/DragGAN/checkpoints -o stylegan2_dogs_1024_pytorch.pkl\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan2_elephants_512_pytorch.pkl -d /content/DragGAN/checkpoints -o stylegan2_elephants_512_pytorch.pkl\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan2_horses_256_pytorch.pkl -d /content/DragGAN/checkpoints -o stylegan2_horses_256_pytorch.pkl\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan2_lions_512_pytorch.pkl -d /content/DragGAN/checkpoints -o stylegan2_lions_512_pytorch.pkl\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DragGAN/resolve/main/stylegan_human_v2_512.pkl -d /content/DragGAN/checkpoints -o stylegan_human_v2_512.pkl\n",
    "\n",
    "!cp /content/PTI/model_{model_id}_image.pkl /content/DragGAN/checkpoints/model_{model_id}_image.pkl\n",
    "!python visualizer_drag_gradio.py --share"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
